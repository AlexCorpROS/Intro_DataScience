{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Машинное обучение для работы с текстами\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация\n",
    "\n",
    "Лемматизация - приведение всех слов текста в начальную форму\n",
    "\n",
    "Существует большое количество библиотек с поддержкой русского языка, мы рассмотрим библиотеку `pymorphy2`. В таких библиотеках находятся предобученные модели для лемматизации текста для русского и украинского языков.\n",
    "\n",
    "https://pymorphy2.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Раскомментировать для установки\n",
    "# !pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='хочу', tag=OpencorporaTag('VERB,impf,tran sing,1per,pres,indc'), normal_form='хотеть', score=1.0, methods_stack=((DictionaryAnalyzer(), 'хочу', 3136, 1),))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymorphy2\n",
    "\n",
    "# Создадим анализатор морфем\n",
    "analyser = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "analyser.parse('думать')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `parse` возвращает массив объектов со следующими атрибутами:\n",
    "-     **tag** -  набор граммем. В данном случае слово думать – это инфинитив глагола (INFN),  несовершенного вида (impf)\n",
    "- **normal_form**– нормального форма слова;\n",
    "- **score** – оценка вероятности того, что данный разбор правильный;\n",
    "- **methods_stack** – тип словаря распарсенного слова с его индексом.\n",
    "\n",
    "Объекты в массиве расположены в порядке убывания атрибута score, поэтому чаще всего следует брать 1й элемент. Получим нормальную форму глагола при помощи атрибута `normal_form`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'думать'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.parse('думал')[0].normal_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация\n",
    "\n",
    "Токенизация - разбивка текста на составляющие (слова, предложения и т.д.)\n",
    "\n",
    "Токенизацию русского текста будем проводить при помощи библиотеки `nltk`. Функция `sent_tokenize` разделяет текст на предложения, `word_tokenize` на слова\n",
    "\n",
    "https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Раскомментировать для установки\n",
    "#!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст, токенизированный по предложениям: ['Петя много знает, т.к. много читает.', 'Хочу быть like Петя.']\n",
      "\n",
      "Текст, токенизированный по словам: ['Петя', 'много', 'знает', ',', 'т.к.', 'много', 'читает', '.', 'Хочу', 'быть', 'like', 'Петя', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Раскомментировать для установки\n",
    "# nltk.download('punkt')\n",
    "text = \"Петя много знает, т.к. много читает. Хочу быть like Петя.\"\n",
    "\n",
    "# Деление на предложения\n",
    "token_sent = nltk.tokenize.sent_tokenize(text, language = 'russian')\n",
    "\n",
    "# Деление на слова \n",
    "token_word = nltk.tokenize.word_tokenize(text, language = 'russian')\n",
    "\n",
    "\n",
    "print(\"Текст, токенизированный по предложениям:\", token_sent)\n",
    "print()\n",
    "print(\"Текст, токенизированный по словам:\", token_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, `nltk` разбил текст на предложения, учитывая сокращение \"т.к.\"\n",
    "\n",
    "\n",
    "Напишем функцию для токенизации текста по словам и последующей его лемматизации и удаления знаков препинания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, drop = False):\n",
    "    analyser = pymorphy2.MorphAnalyzer()\n",
    "    token_word = nltk.tokenize.word_tokenize(text, language = 'russian')\n",
    "    \n",
    "    # Создадим словарь из-за того, что операция проверки значения работает за O(1)\n",
    "    punctuation_array = [',', '-', '.', ':', ';', '?', '!', '\"', \"'\", '(', ')']\n",
    "    punctuation_dict = {i : 0 for i in punctuation_array}\n",
    "    \n",
    "    preprocessed_text = []\n",
    "    for word in token_word:\n",
    "        if drop:\n",
    "            if word not in punctuation_dict.keys():\n",
    "                preprocessed_text.append(analyser.parse(word)[0].normal_form)\n",
    "        else: \n",
    "            preprocessed_text.append(analyser.parse(word)[0].normal_form)\n",
    "                    \n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработаем стихотворение Александра Блока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ночь',\n",
       " ',',\n",
       " 'улица',\n",
       " ',',\n",
       " 'фонарь',\n",
       " ',',\n",
       " 'аптека',\n",
       " ',',\n",
       " 'бессмысленный',\n",
       " 'и',\n",
       " 'тусклый',\n",
       " 'свет',\n",
       " '.',\n",
       " 'живить',\n",
       " 'ещё',\n",
       " 'хоть',\n",
       " 'четверть',\n",
       " 'век',\n",
       " '—',\n",
       " 'всё',\n",
       " 'быть',\n",
       " 'так.',\n",
       " 'исход',\n",
       " 'нет',\n",
       " '.',\n",
       " 'умереть',\n",
       " '—',\n",
       " 'начать',\n",
       " 'опять',\n",
       " 'сначала',\n",
       " 'и',\n",
       " 'повториться',\n",
       " 'всё',\n",
       " ',',\n",
       " 'как',\n",
       " 'встарь',\n",
       " ':',\n",
       " 'ночь',\n",
       " ',',\n",
       " 'ледяной',\n",
       " 'рябь',\n",
       " 'канал',\n",
       " ',',\n",
       " 'аптека',\n",
       " ',',\n",
       " 'улица',\n",
       " ',',\n",
       " 'фонарь',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Ночь, улица, фонарь, аптека,\n",
    "Бессмысленный и тусклый свет.\n",
    "Живи еще хоть четверть века —\n",
    "Всё будет так. Исхода нет.\n",
    "\n",
    "Умрешь — начнешь опять сначала\n",
    "И повторится всё, как встарь:\n",
    "Ночь, ледяная рябь канала,\n",
    "Аптека, улица, фонарь.\"\"\"\n",
    "\n",
    "\n",
    "preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8212"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(preprocess_text(text)[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные и постановка задачи\n",
    "\n",
    "Весь материал ниже будет показан на примере части данных из корпуса русских твитов https://study.mokoron.com/  http://www.swsys.ru/index.php?page=article&id=3962&lang=\n",
    "\n",
    "\n",
    "База данных состоит из 12 столбцов:\n",
    "\n",
    "- id: уникальный номер сообщения в системе twitter;\n",
    "- tdate: дата публикации сообщения (твита);\n",
    "- tmane: имя пользователя, опубликовавшего сообщение;\n",
    "- ttext:  текст сообщения (твита);\n",
    "- ttype: поле в котором в дальнейшем будет указано к кому классу относится твит (положительный, отрицательный, нейтральный);\n",
    "- trep: количество реплаев к данному сообщению. В настоящий момент API твиттера не отдает эту информацию;\n",
    "- trtw: количество ретвитов;\n",
    "- tfav: число сколько раз данное сообщение было добавлено в избранное другими пользователями;\n",
    "- tstcount: число всех сообщений пользователя в сети twitter;\n",
    "- tfol: количество фоловеров пользователя (тех людей, которые читают пользователя);\n",
    "- tfrien: количество друзей пользователя (те люди, которых читает пользователь);\n",
    "- listcount: количество листов-подписок в которые добавлен твиттер-пользователь.\n",
    "\n",
    "\n",
    "Наша задача предсказать тип твита: позитивный или негативный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tdate</th>\n",
       "      <th>tmane</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "      <th>trep</th>\n",
       "      <th>tfav</th>\n",
       "      <th>trtw</th>\n",
       "      <th>tstcount</th>\n",
       "      <th>tfol</th>\n",
       "      <th>tfrien</th>\n",
       "      <th>listcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3613</th>\n",
       "      <td>410304092859531264</td>\n",
       "      <td>1386659093</td>\n",
       "      <td>Lenookkk</td>\n",
       "      <td>Лежу спокойно в кровати, и тут уведомление из ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5281</td>\n",
       "      <td>747</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668</th>\n",
       "      <td>410779530778136577</td>\n",
       "      <td>1386772446</td>\n",
       "      <td>ekaterinab172</td>\n",
       "      <td>Мужчины храпят во сне, чтобы защитить своих от...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>410856223907393537</td>\n",
       "      <td>1386790731</td>\n",
       "      <td>ChernushoVa514</td>\n",
       "      <td>капец..как уснуть?это учащенное сердцебиение у...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8979</th>\n",
       "      <td>410032963330768896</td>\n",
       "      <td>1386594451</td>\n",
       "      <td>dotdroid</td>\n",
       "      <td>@Oh_Philip17 @corpz_ @aka_opex так ты чо все т...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40694</td>\n",
       "      <td>441</td>\n",
       "      <td>190</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5588</th>\n",
       "      <td>410796733912739840</td>\n",
       "      <td>1386776548</td>\n",
       "      <td>Strange_eternal</td>\n",
       "      <td>@WaveOfSweetFire  Хорошее желание * сказал я, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20803</td>\n",
       "      <td>600</td>\n",
       "      <td>688</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>412817869999968256</td>\n",
       "      <td>1387258424</td>\n",
       "      <td>TheMaDogg</td>\n",
       "      <td>xxx: Моя жизнь принадлежит Орде!!!! / ххх: а к...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69216</td>\n",
       "      <td>3443</td>\n",
       "      <td>6815</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4849</th>\n",
       "      <td>412193238062465024</td>\n",
       "      <td>1387109500</td>\n",
       "      <td>Love_Batman69</td>\n",
       "      <td>RT @Fereira1999: Люди блять вы охерели со всем...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1692</td>\n",
       "      <td>1181</td>\n",
       "      <td>1186</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6977</th>\n",
       "      <td>410866218976165888</td>\n",
       "      <td>1386793114</td>\n",
       "      <td>Raziiiiiiiii</td>\n",
       "      <td>RT @karrimov: Кстати, GTA: San Andreas вышла в...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7641</td>\n",
       "      <td>160</td>\n",
       "      <td>936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>409046441630629888</td>\n",
       "      <td>1386359246</td>\n",
       "      <td>zkate97</td>\n",
       "      <td>@elizabettlapo а еще сумасшедшие танцы перед з...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>725</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6918</th>\n",
       "      <td>409773726994292736</td>\n",
       "      <td>1386532644</td>\n",
       "      <td>MaxDisk</td>\n",
       "      <td>@arvidOS @Alex_Shvarz @orion_575 та нет. Есть ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117836</td>\n",
       "      <td>1755</td>\n",
       "      <td>638</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id       tdate            tmane  \\\n",
       "3613  410304092859531264  1386659093         Lenookkk   \n",
       "7668  410779530778136577  1386772446    ekaterinab172   \n",
       "1538  410856223907393537  1386790731   ChernushoVa514   \n",
       "8979  410032963330768896  1386594451         dotdroid   \n",
       "5588  410796733912739840  1386776548  Strange_eternal   \n",
       "520   412817869999968256  1387258424        TheMaDogg   \n",
       "4849  412193238062465024  1387109500    Love_Batman69   \n",
       "6977  410866218976165888  1386793114     Raziiiiiiiii   \n",
       "9595  409046441630629888  1386359246          zkate97   \n",
       "6918  409773726994292736  1386532644          MaxDisk   \n",
       "\n",
       "                                                  ttext  ttype  trep  tfav  \\\n",
       "3613  Лежу спокойно в кровати, и тут уведомление из ...     -1     0     0   \n",
       "7668  Мужчины храпят во сне, чтобы защитить своих от...      1     0     0   \n",
       "1538  капец..как уснуть?это учащенное сердцебиение у...     -1     0     0   \n",
       "8979  @Oh_Philip17 @corpz_ @aka_opex так ты чо все т...      1     0     0   \n",
       "5588  @WaveOfSweetFire  Хорошее желание * сказал я, ...      1     0     0   \n",
       "520   xxx: Моя жизнь принадлежит Орде!!!! / ххх: а к...     -1     0     0   \n",
       "4849  RT @Fereira1999: Люди блять вы охерели со всем...     -1     0     3   \n",
       "6977  RT @karrimov: Кстати, GTA: San Andreas вышла в...      1     0     3   \n",
       "9595  @elizabettlapo а еще сумасшедшие танцы перед з...      1     0     0   \n",
       "6918  @arvidOS @Alex_Shvarz @orion_575 та нет. Есть ...      1     0     0   \n",
       "\n",
       "      trtw  tstcount  tfol  tfrien  listcount  \n",
       "3613     0      5281   747      12          3  \n",
       "7668     0         4     0       2          0  \n",
       "1538     0       147     8       8          0  \n",
       "8979     0     40694   441     190         15  \n",
       "5588     0     20803   600     688         11  \n",
       "520      0     69216  3443    6815          8  \n",
       "4849     0      1692  1181    1186          6  \n",
       "6977     0      7641   160     936          1  \n",
       "9595     0       725    50      46          0  \n",
       "6918     0    117836  1755     638        146  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Читаем данные\n",
    "data = pd.read_csv('twitter_corpus.csv')\n",
    "data.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регулярные выражения\n",
    "\n",
    "В модуле Python вы уже работали с библиотекой `re` и регулярными выражениями. Если забыли, держите шпаргалку https://www.debuggex.com/cheatsheet/regex/python\n",
    "\n",
    "**Как вы думаете, что можно выделить из текста, чтобы уменьшить размерность и при этом не потерять важной информации?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Хотела написать ванили ванильную но не вышло '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def parce_text(text):\n",
    "    res = re.findall(\"['А-яёË']+\", text)\n",
    "    # Приведем в строку\n",
    "    total_str = ''\n",
    "    for word in res:\n",
    "        total_str += word + ' '\n",
    "    return total_str\n",
    "\n",
    "# Как можно изменить функцию выше, чтобы парсить смайлики?\n",
    "s = 'Хотела написать ванили ванильную но не вышло;('\n",
    "\n",
    "parce_text(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tdate</th>\n",
       "      <th>tmane</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "      <th>trep</th>\n",
       "      <th>tfav</th>\n",
       "      <th>trtw</th>\n",
       "      <th>tstcount</th>\n",
       "      <th>tfol</th>\n",
       "      <th>tfrien</th>\n",
       "      <th>listcount</th>\n",
       "      <th>text_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>411792431701434369</td>\n",
       "      <td>1387013941</td>\n",
       "      <td>Flyyyy4</td>\n",
       "      <td>@milena_galk и я очень( сегодня приснилось про...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8523</td>\n",
       "      <td>127</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>и я очень сегодня приснилось просто</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>410300052088061952</td>\n",
       "      <td>1386658130</td>\n",
       "      <td>walter_tanyaZ</td>\n",
       "      <td>Я вчера нарисовал его :-)  оцените пжалки http...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9232</td>\n",
       "      <td>271</td>\n",
       "      <td>216</td>\n",
       "      <td>5</td>\n",
       "      <td>Я вчера нарисовал его оцените пжалки</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>413932462172299264</td>\n",
       "      <td>1387524164</td>\n",
       "      <td>a_ni_dam</td>\n",
       "      <td>Казавшийся нормистый фик скатился в дерьмо((</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12576</td>\n",
       "      <td>71</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>Казавшийся нормистый фик скатился в дерьмо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>413305023741710336</td>\n",
       "      <td>1387374571</td>\n",
       "      <td>vika30011999</td>\n",
       "      <td>надо идти покупать вещи к новому году,лень:(</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3569</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>надо идти покупать вещи к новому году лень</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>409845234114498560</td>\n",
       "      <td>1386549693</td>\n",
       "      <td>jekaterinaonu</td>\n",
       "      <td>Даня заболел :( каждый день что-то случается....</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>886</td>\n",
       "      <td>51</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>Даня заболел каждый день что то случается</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>415846621067231232</td>\n",
       "      <td>1387980535</td>\n",
       "      <td>v_kimo</td>\n",
       "      <td>Друзья как можно было написать трек ОТРЫВКИ ИЗ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1670</td>\n",
       "      <td>1141</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>Друзья как можно было написать трек ОТРЫВКИ ИЗ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6136</th>\n",
       "      <td>410870321315450880</td>\n",
       "      <td>1386794092</td>\n",
       "      <td>ian_vladimirov</td>\n",
       "      <td>Доставило: «В последний раз, когда создатель L...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2293</td>\n",
       "      <td>4061</td>\n",
       "      <td>102</td>\n",
       "      <td>43</td>\n",
       "      <td>Доставило В последний раз когда создатель Бред...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>413825881392828416</td>\n",
       "      <td>1387498753</td>\n",
       "      <td>jolliss_kierce</td>\n",
       "      <td>Одиночество это когда в онлайне 50 друзей, а н...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>575</td>\n",
       "      <td>209</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>Одиночество это когда в онлайне друзей а напис...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6498</th>\n",
       "      <td>409061426582786048</td>\n",
       "      <td>1386362818</td>\n",
       "      <td>maskuznetsova</td>\n",
       "      <td>Сегодня игра ЦСКА против СКА понравилась! Всег...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1619</td>\n",
       "      <td>152</td>\n",
       "      <td>162</td>\n",
       "      <td>2</td>\n",
       "      <td>Сегодня игра ЦСКА против СКА понравилась Всегд...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>410380789801816064</td>\n",
       "      <td>1386677379</td>\n",
       "      <td>buzazuwedup</td>\n",
       "      <td>— блин, просто сплошной праздник какой-то у на...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>616</td>\n",
       "      <td>188</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>блин просто сплошной праздник какой то у нас в...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id       tdate           tmane  \\\n",
       "2924  411792431701434369  1387013941         Flyyyy4   \n",
       "6149  410300052088061952  1386658130   walter_tanyaZ   \n",
       "1882  413932462172299264  1387524164        a_ni_dam   \n",
       "2212  413305023741710336  1387374571    vika30011999   \n",
       "1014  409845234114498560  1386549693   jekaterinaonu   \n",
       "3787  415846621067231232  1387980535          v_kimo   \n",
       "6136  410870321315450880  1386794092  ian_vladimirov   \n",
       "2107  413825881392828416  1387498753  jolliss_kierce   \n",
       "6498  409061426582786048  1386362818   maskuznetsova   \n",
       "5309  410380789801816064  1386677379     buzazuwedup   \n",
       "\n",
       "                                                  ttext  ttype  trep  tfav  \\\n",
       "2924  @milena_galk и я очень( сегодня приснилось про...     -1     0     0   \n",
       "6149  Я вчера нарисовал его :-)  оцените пжалки http...      1     0     0   \n",
       "1882       Казавшийся нормистый фик скатился в дерьмо((     -1     0     0   \n",
       "2212       надо идти покупать вещи к новому году,лень:(     -1     0     0   \n",
       "1014   Даня заболел :( каждый день что-то случается....     -1     0     0   \n",
       "3787  Друзья как можно было написать трек ОТРЫВКИ ИЗ...     -1     0     0   \n",
       "6136  Доставило: «В последний раз, когда создатель L...      1     0     0   \n",
       "2107  Одиночество это когда в онлайне 50 друзей, а н...     -1     0     0   \n",
       "6498  Сегодня игра ЦСКА против СКА понравилась! Всег...      1     0     0   \n",
       "5309  — блин, просто сплошной праздник какой-то у на...      1     0     0   \n",
       "\n",
       "      trtw  tstcount  tfol  tfrien  listcount  \\\n",
       "2924     1      8523   127      87          0   \n",
       "6149     0      9232   271     216          5   \n",
       "1882     0     12576    71      30          0   \n",
       "2212     0      3569    49      65          0   \n",
       "1014     0       886    51      61          0   \n",
       "3787     0      1670  1141     112          2   \n",
       "6136     0      2293  4061     102         43   \n",
       "2107     0       575   209     197          0   \n",
       "6498     0      1619   152     162          2   \n",
       "5309     0       616   188     198          0   \n",
       "\n",
       "                                            text_parsed  \n",
       "2924               и я очень сегодня приснилось просто   \n",
       "6149              Я вчера нарисовал его оцените пжалки   \n",
       "1882        Казавшийся нормистый фик скатился в дерьмо   \n",
       "2212        надо идти покупать вещи к новому году лень   \n",
       "1014         Даня заболел каждый день что то случается   \n",
       "3787  Друзья как можно было написать трек ОТРЫВКИ ИЗ...  \n",
       "6136  Доставило В последний раз когда создатель Бред...  \n",
       "2107  Одиночество это когда в онлайне друзей а напис...  \n",
       "6498  Сегодня игра ЦСКА против СКА понравилась Всегд...  \n",
       "5309  блин просто сплошной праздник какой то у нас в...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_parsed'] = data['ttext'].apply(lambda x: parce_text(x))\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words\n",
    "\n",
    "Машины работают на языке математики, поэтому они не могут воспринимать текст в виде последовательности символов, которая понятна человеку. Переведем текст в формат более привычный для машины - вектора.\n",
    "\n",
    "**Bag of words (мешок слов)** - переводит текст в вектор, учитывая частоту встречаемости в нем слов, но не учитывает их последовательность.\n",
    "\n",
    "В случае когда текстов несколько bag of words перобразует их в матрицу, где строки это тексты, а столбцы - уникальные слова.\n",
    "\n",
    "Рассмотрим на примере:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ехать',\n",
       " 'грек',\n",
       " 'через',\n",
       " 'река',\n",
       " ',',\n",
       " 'видеть',\n",
       " 'грек',\n",
       " 'в',\n",
       " 'река',\n",
       " 'рак',\n",
       " ',',\n",
       " 'сунуть',\n",
       " 'грек',\n",
       " 'рука',\n",
       " 'в',\n",
       " 'река',\n",
       " ',',\n",
       " 'рак',\n",
       " 'за',\n",
       " 'рука',\n",
       " 'грек',\n",
       " 'цап',\n",
       " '!']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Исходный текст\n",
    "text = 'Ехал Грека через реку, видит Грека в реке рак, сунул грека руку в реку, рак за руку Греку цап!'\n",
    "\n",
    "# Токенизируем и лемматизируем и текст\n",
    "new_text = preprocess_text(text)\n",
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'грек': 4, 'река': 3, ',': 3, 'в': 2, 'рак': 2, 'рука': 2, 'ехать': 1, 'через': 1, 'видеть': 1, 'сунуть': 1, 'за': 1, 'цап': 1, '!': 1})\n",
      "Мешок слов: [1, 4, 1, 3, 3, 1, 2, 2, 1, 2, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Посчитаем кол-во вхождений каждого слова\n",
    "from collections import Counter\n",
    "\n",
    "cnt = Counter(new_text)\n",
    "print(cnt)\n",
    "\n",
    "# Выделим массив значений\n",
    "bag_of_words = list(cnt.values())\n",
    "print(\"Мешок слов:\", bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words в sklearn\n",
    "\n",
    "В библиотеке `sklearn` есть модуль `features_extraction.text`, предназначенный для предобработки текстовых данных https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text\n",
    "\n",
    "Для создания мешка слов для наших данных нам потребуется функция `CountVectorizer()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32637)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cnt = CountVectorizer()\n",
    "\n",
    "bag_of_words_sklearn = cnt.fit_transform(data['ttext'].values)\n",
    "\n",
    "print(bag_of_words_sklearn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "Для измерения важности слова в текса, являющегося частью корпуса применяется TF-IDF (от англ. TF — term frequency, IDF — inverse document frequency). TF отвечает за упоминание слов в конкретном тексте, а IDF за частоту употребления слова во всем корпусе, таким образом слова, неважные для вообще всех документов, например, предлоги или междометия — получат очень низкий вес TF-IDF (потому что часто встречаются во всех-всех документах), а важные — высокий.\n",
    "\n",
    "TF-IDF часто применяется в SEO оптимизации текстов\n",
    "\n",
    "TF-IDF рассчитываетсся как: $TF-IDF = TF * IDF$; \n",
    "\n",
    "$$TF = \\frac{c}{N}$$, где c - кол-во употребления слова, N - общее кол-во слов в тексте\n",
    "\n",
    "$$IDF = \\log_{a}{\\frac{D}{d}}$$, где а - основание логарифма, выбирающееся от задачи, чаще всего полагают а = 2 или а = 10, D - общее кол-во текстов в корпусе, d - кол-во текстов, в которых употребляется слово\n",
    "\n",
    "\n",
    "В библиотеке `sklearn` есть встроенная функция `TfidfVectorizer()` для подсчета TF-IDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32637)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_cnt = TfidfVectorizer()\n",
    "\n",
    "tfidf = tfidf_cnt.fit_transform(data['ttext'].values)\n",
    "\n",
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно! Если данные разделены на тестовую и обучающую выборки, то Tfidf стоит запускать только на обучающей выборке**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эмбеддинги слов\n",
    "\n",
    "Слова в предложении сами по себе не имеют смысла, она заключается в контексте, свойствах и т.д. Выше при переводе слова в вектор это не учитывалось. \n",
    "\n",
    "При работе с нетабличными данными, их переводят **в векторное представление**, эмбеддинги слов (word embeddings) - частный случай таких представлений.\n",
    "\n",
    "Эмбеддинги содержат в себе информацию о соотношении слов в тексте и их свойствах, например свойства слова \"пожарный\": \"мужчина\", \"герой\", \"огонь\" и т.д.\n",
    "\n",
    "Эти данные нужны для определения схожести векторных представлений слов. Как вы помните, схожесть векторов определяется расстоянием между ними. Например, мы интуитивно понимаем, что слова \"лопата\" и \"вилы\" гораздо более схожи, чем слова \"дробовик\" и \"валентинка\", они употребляются в похожем контексте\n",
    "\n",
    "То как получаются такие векторы - за пределами нашего курса, материалы по этой теме: https://habr.com/ru/company/ods/blog/329410/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация твитов\n",
    "\n",
    "Вернемся к задачи классификации твитов, в качесте признаков выступают слова в корпусе и их TF-IDF. Обучим логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf, data['ttype'], test_size = 0.2, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
